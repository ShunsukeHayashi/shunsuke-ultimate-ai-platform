#!/usr/bin/env python3
"""
ã‚·ãƒ¥ãƒ³ã‚¹ã‚±å¼ãƒªã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒ¼ - Ultimate ShunsukeModel Ecosystem

ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ã®ä½¿ç”¨çŠ¶æ³ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ç›£è¦–ã—ã€
ç•°å¸¸æ¤œçŸ¥ã¨ã‚¢ãƒ©ãƒ¼ãƒˆç™ºç”Ÿã‚’è¡Œã†é«˜ç²¾åº¦ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 
"""

import asyncio
import psutil
import logging
import time
import json
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Callable, Set, Tuple
from datetime import datetime, timedelta
from pathlib import Path
from collections import deque, defaultdict
import numpy as np
import platform
import os
import threading
from enum import Enum
import socket
import aiohttp
from concurrent.futures import ThreadPoolExecutor


class ResourceType(Enum):
    """ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—"""
    CPU = "cpu"
    MEMORY = "memory"
    DISK = "disk"
    NETWORK = "network"
    PROCESS = "process"
    SYSTEM = "system"


class AlertLevel(Enum):
    """ã‚¢ãƒ©ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«"""
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"
    EMERGENCY = "emergency"


@dataclass
class ResourceMetrics:
    """ãƒªã‚½ãƒ¼ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    timestamp: datetime
    resource_type: ResourceType
    metrics: Dict[str, Any]
    usage_percent: float
    status: str = "normal"
    alerts: List[Dict[str, Any]] = field(default_factory=list)


@dataclass
class CPUMetrics:
    """CPUãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    usage_percent: float
    usage_per_core: List[float]
    frequency_current: float
    frequency_max: float
    temperature: Optional[float]
    load_average: Tuple[float, float, float]
    context_switches: int
    interrupts: int
    processes: int
    threads: int


@dataclass
class MemoryMetrics:
    """ãƒ¡ãƒ¢ãƒªãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    total: int
    available: int
    used: int
    free: int
    percent: float
    swap_total: int
    swap_used: int
    swap_free: int
    swap_percent: float
    cached: int
    buffers: int


@dataclass
class DiskMetrics:
    """ãƒ‡ã‚£ã‚¹ã‚¯ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    partitions: List[Dict[str, Any]]
    io_counters: Dict[str, Any]
    usage_per_partition: Dict[str, float]
    read_speed: float  # MB/s
    write_speed: float  # MB/s
    io_wait: float


@dataclass
class NetworkMetrics:
    """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    interfaces: Dict[str, Dict[str, Any]]
    bytes_sent: int
    bytes_recv: int
    packets_sent: int
    packets_recv: int
    upload_speed: float  # MB/s
    download_speed: float  # MB/s
    connections: int
    connection_states: Dict[str, int]


@dataclass
class ProcessMetrics:
    """ãƒ—ãƒ­ã‚»ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    pid: int
    name: str
    cpu_percent: float
    memory_percent: float
    memory_info: Dict[str, Any]
    num_threads: int
    status: str
    create_time: float
    io_counters: Optional[Dict[str, Any]]
    open_files: int
    connections: int


@dataclass
class Alert:
    """ã‚¢ãƒ©ãƒ¼ãƒˆ"""
    timestamp: datetime
    resource_type: ResourceType
    alert_level: AlertLevel
    metric_name: str
    current_value: float
    threshold: float
    message: str
    details: Dict[str, Any] = field(default_factory=dict)
    resolved: bool = False
    resolved_at: Optional[datetime] = None


class ResourceMonitor:
    """
    ã‚·ãƒ¥ãƒ³ã‚¹ã‚±å¼ãƒªã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒ¼
    
    æ©Ÿèƒ½:
    - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–
    - ç•°å¸¸æ¤œçŸ¥ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ
    - ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
    - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬
    - è‡ªå‹•æœ€é©åŒ–ææ¡ˆ
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        self.logger = logging.getLogger(__name__)
        
        # ç›£è¦–è¨­å®š
        self.monitoring_interval = self.config.get('interval', 1.0)  # ç§’
        self.history_size = self.config.get('history_size', 3600)  # 1æ™‚é–“åˆ†
        
        # ã—ãã„å€¤è¨­å®š
        self.thresholds = self.config.get('thresholds', {
            'cpu': {'warning': 70, 'critical': 90},
            'memory': {'warning': 80, 'critical': 95},
            'disk': {'warning': 85, 'critical': 95},
            'network': {'warning': 80, 'critical': 95}
        })
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹å±¥æ­´
        self.metrics_history = {
            ResourceType.CPU: deque(maxlen=self.history_size),
            ResourceType.MEMORY: deque(maxlen=self.history_size),
            ResourceType.DISK: deque(maxlen=self.history_size),
            ResourceType.NETWORK: deque(maxlen=self.history_size),
            ResourceType.PROCESS: deque(maxlen=self.history_size)
        }
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†
        self.active_alerts: Dict[str, Alert] = {}
        self.alert_history: deque = deque(maxlen=1000)
        self.alert_callbacks: List[Callable] = []
        
        # ç›£è¦–ã‚¿ã‚¹ã‚¯
        self.monitoring_task: Optional[asyncio.Task] = None
        self.is_monitoring = False
        self.monitor_lock = threading.Lock()
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            'start_time': None,
            'total_alerts': 0,
            'alerts_by_level': defaultdict(int),
            'alerts_by_type': defaultdict(int)
        }
        
        # ãƒ—ãƒ­ã‚»ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self.process_cache = {}
        self.process_cache_ttl = 5  # ç§’
        
        # ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«
        self.executor = ThreadPoolExecutor(max_workers=4)
    
    async def start_monitoring(self):
        """ç›£è¦–é–‹å§‹"""
        with self.monitor_lock:
            if self.is_monitoring:
                self.logger.warning("Monitoring already started")
                return
            
            self.is_monitoring = True
            self.stats['start_time'] = datetime.now()
            self.monitoring_task = asyncio.create_task(self._monitoring_loop())
            
            self.logger.info("Resource monitoring started")
    
    async def stop_monitoring(self):
        """ç›£è¦–åœæ­¢"""
        with self.monitor_lock:
            if not self.is_monitoring:
                return
            
            self.is_monitoring = False
            
            if self.monitoring_task:
                self.monitoring_task.cancel()
                try:
                    await self.monitoring_task
                except asyncio.CancelledError:
                    pass
            
            self.logger.info("Resource monitoring stopped")
    
    async def _monitoring_loop(self):
        """ç›£è¦–ãƒ«ãƒ¼ãƒ—"""
        while self.is_monitoring:
            try:
                # å„ãƒªã‚½ãƒ¼ã‚¹ã®ç›£è¦–
                await asyncio.gather(
                    self._monitor_cpu(),
                    self._monitor_memory(),
                    self._monitor_disk(),
                    self._monitor_network(),
                    self._monitor_processes()
                )
                
                # ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
                await self._check_alerts()
                
                # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
                await self._analyze_trends()
                
                # å¾…æ©Ÿ
                await asyncio.sleep(self.monitoring_interval)
                
            except Exception as e:
                self.logger.error(f"Monitoring error: {e}")
                await asyncio.sleep(self.monitoring_interval)
    
    async def _monitor_cpu(self):
        """CPUç›£è¦–"""
        try:
            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=0.1)
            cpu_percent_per_core = psutil.cpu_percent(interval=0.1, percpu=True)
            
            # CPUå‘¨æ³¢æ•°
            cpu_freq = psutil.cpu_freq()
            freq_current = cpu_freq.current if cpu_freq else 0
            freq_max = cpu_freq.max if cpu_freq else 0
            
            # CPUæ¸©åº¦ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
            temperature = None
            try:
                if hasattr(psutil, 'sensors_temperatures'):
                    temps = psutil.sensors_temperatures()
                    if temps:
                        # æœ€åˆã®ã‚»ãƒ³ã‚µãƒ¼ã®æ¸©åº¦ã‚’å–å¾—
                        for name, entries in temps.items():
                            if entries:
                                temperature = entries[0].current
                                break
            except:
                pass
            
            # ãƒ­ãƒ¼ãƒ‰ã‚¢ãƒ™ãƒ¬ãƒ¼ã‚¸
            load_avg = os.getloadavg() if hasattr(os, 'getloadavg') else (0, 0, 0)
            
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¹ã‚¤ãƒƒãƒã¨å‰²ã‚Šè¾¼ã¿
            cpu_stats = psutil.cpu_stats()
            
            # ãƒ—ãƒ­ã‚»ã‚¹æ•°ã¨ã‚¹ãƒ¬ãƒƒãƒ‰æ•°
            process_count = len(psutil.pids())
            thread_count = threading.active_count()
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä½œæˆ
            metrics = CPUMetrics(
                usage_percent=cpu_percent,
                usage_per_core=cpu_percent_per_core,
                frequency_current=freq_current,
                frequency_max=freq_max,
                temperature=temperature,
                load_average=load_avg,
                context_switches=cpu_stats.ctx_switches,
                interrupts=cpu_stats.interrupts,
                processes=process_count,
                threads=thread_count
            )
            
            # å±¥æ­´ã«è¿½åŠ 
            resource_metrics = ResourceMetrics(
                timestamp=datetime.now(),
                resource_type=ResourceType.CPU,
                metrics=metrics.__dict__,
                usage_percent=cpu_percent
            )
            
            self.metrics_history[ResourceType.CPU].append(resource_metrics)
            
            # ã—ãã„å€¤ãƒã‚§ãƒƒã‚¯
            await self._check_threshold(ResourceType.CPU, 'usage', cpu_percent)
            
        except Exception as e:
            self.logger.error(f"CPU monitoring error: {e}")
    
    async def _monitor_memory(self):
        """ãƒ¡ãƒ¢ãƒªç›£è¦–"""
        try:
            # ç‰©ç†ãƒ¡ãƒ¢ãƒª
            mem = psutil.virtual_memory()
            
            # ã‚¹ãƒ¯ãƒƒãƒ—ãƒ¡ãƒ¢ãƒª
            swap = psutil.swap_memory()
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä½œæˆ
            metrics = MemoryMetrics(
                total=mem.total,
                available=mem.available,
                used=mem.used,
                free=mem.free,
                percent=mem.percent,
                swap_total=swap.total,
                swap_used=swap.used,
                swap_free=swap.free,
                swap_percent=swap.percent,
                cached=getattr(mem, 'cached', 0),
                buffers=getattr(mem, 'buffers', 0)
            )
            
            # å±¥æ­´ã«è¿½åŠ 
            resource_metrics = ResourceMetrics(
                timestamp=datetime.now(),
                resource_type=ResourceType.MEMORY,
                metrics=metrics.__dict__,
                usage_percent=mem.percent
            )
            
            self.metrics_history[ResourceType.MEMORY].append(resource_metrics)
            
            # ã—ãã„å€¤ãƒã‚§ãƒƒã‚¯
            await self._check_threshold(ResourceType.MEMORY, 'usage', mem.percent)
            await self._check_threshold(ResourceType.MEMORY, 'swap', swap.percent)
            
        except Exception as e:
            self.logger.error(f"Memory monitoring error: {e}")
    
    async def _monitor_disk(self):
        """ãƒ‡ã‚£ã‚¹ã‚¯ç›£è¦–"""
        try:
            # ãƒ‡ã‚£ã‚¹ã‚¯ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³
            partitions = []
            usage_per_partition = {}
            
            for partition in psutil.disk_partitions():
                try:
                    usage = psutil.disk_usage(partition.mountpoint)
                    partition_info = {
                        'device': partition.device,
                        'mountpoint': partition.mountpoint,
                        'fstype': partition.fstype,
                        'total': usage.total,
                        'used': usage.used,
                        'free': usage.free,
                        'percent': usage.percent
                    }
                    partitions.append(partition_info)
                    usage_per_partition[partition.device] = usage.percent
                except:
                    continue
            
            # I/Oã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
            io_counters = psutil.disk_io_counters()
            io_dict = {
                'read_count': io_counters.read_count,
                'write_count': io_counters.write_count,
                'read_bytes': io_counters.read_bytes,
                'write_bytes': io_counters.write_bytes,
                'read_time': io_counters.read_time,
                'write_time': io_counters.write_time
            } if io_counters else {}
            
            # I/Oé€Ÿåº¦è¨ˆç®—ï¼ˆå‰å›ã¨ã®å·®åˆ†ï¼‰
            read_speed = 0
            write_speed = 0
            
            if ResourceType.DISK in self.metrics_history and self.metrics_history[ResourceType.DISK]:
                last_metrics = self.metrics_history[ResourceType.DISK][-1]
                if 'io_counters' in last_metrics.metrics:
                    last_io = last_metrics.metrics['io_counters']
                    time_diff = (datetime.now() - last_metrics.timestamp).total_seconds()
                    
                    if time_diff > 0 and io_counters:
                        read_speed = (io_counters.read_bytes - last_io.get('read_bytes', 0)) / time_diff / 1024 / 1024
                        write_speed = (io_counters.write_bytes - last_io.get('write_bytes', 0)) / time_diff / 1024 / 1024
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä½œæˆ
            metrics = DiskMetrics(
                partitions=partitions,
                io_counters=io_dict,
                usage_per_partition=usage_per_partition,
                read_speed=max(0, read_speed),
                write_speed=max(0, write_speed),
                io_wait=0  # TODO: ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å›ºæœ‰ã®å®Ÿè£…
            )
            
            # æœ€å¤§ä½¿ç”¨ç‡ã‚’è¨ˆç®—
            max_usage = max(usage_per_partition.values()) if usage_per_partition else 0
            
            # å±¥æ­´ã«è¿½åŠ 
            resource_metrics = ResourceMetrics(
                timestamp=datetime.now(),
                resource_type=ResourceType.DISK,
                metrics=metrics.__dict__,
                usage_percent=max_usage
            )
            
            self.metrics_history[ResourceType.DISK].append(resource_metrics)
            
            # ã—ãã„å€¤ãƒã‚§ãƒƒã‚¯ï¼ˆå„ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ï¼‰
            for device, usage in usage_per_partition.items():
                await self._check_threshold(ResourceType.DISK, f'usage_{device}', usage)
            
        except Exception as e:
            self.logger.error(f"Disk monitoring error: {e}")
    
    async def _monitor_network(self):
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç›£è¦–"""
        try:
            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
            interfaces = {}
            for iface, addrs in psutil.net_if_addrs().items():
                interface_info = {
                    'addresses': []
                }
                for addr in addrs:
                    interface_info['addresses'].append({
                        'family': addr.family.name,
                        'address': addr.address,
                        'netmask': addr.netmask,
                        'broadcast': addr.broadcast
                    })
                interfaces[iface] = interface_info
            
            # I/Oã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
            net_io = psutil.net_io_counters()
            
            # æ¥ç¶šæƒ…å ±
            connections = psutil.net_connections()
            connection_states = defaultdict(int)
            for conn in connections:
                if conn.status:
                    connection_states[conn.status] += 1
            
            # é€Ÿåº¦è¨ˆç®—
            upload_speed = 0
            download_speed = 0
            
            if ResourceType.NETWORK in self.metrics_history and self.metrics_history[ResourceType.NETWORK]:
                last_metrics = self.metrics_history[ResourceType.NETWORK][-1]
                time_diff = (datetime.now() - last_metrics.timestamp).total_seconds()
                
                if time_diff > 0:
                    last_sent = last_metrics.metrics.get('bytes_sent', 0)
                    last_recv = last_metrics.metrics.get('bytes_recv', 0)
                    
                    upload_speed = (net_io.bytes_sent - last_sent) / time_diff / 1024 / 1024
                    download_speed = (net_io.bytes_recv - last_recv) / time_diff / 1024 / 1024
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä½œæˆ
            metrics = NetworkMetrics(
                interfaces=interfaces,
                bytes_sent=net_io.bytes_sent,
                bytes_recv=net_io.bytes_recv,
                packets_sent=net_io.packets_sent,
                packets_recv=net_io.packets_recv,
                upload_speed=max(0, upload_speed),
                download_speed=max(0, download_speed),
                connections=len(connections),
                connection_states=dict(connection_states)
            )
            
            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä½¿ç”¨ç‡ã®æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
            # ä»®å®š: 1Gbps = 125MB/s ã‚’åŸºæº–
            max_bandwidth = 125  # MB/s
            network_usage = ((upload_speed + download_speed) / max_bandwidth) * 100
            
            # å±¥æ­´ã«è¿½åŠ 
            resource_metrics = ResourceMetrics(
                timestamp=datetime.now(),
                resource_type=ResourceType.NETWORK,
                metrics=metrics.__dict__,
                usage_percent=min(100, network_usage)
            )
            
            self.metrics_history[ResourceType.NETWORK].append(resource_metrics)
            
        except Exception as e:
            self.logger.error(f"Network monitoring error: {e}")
    
    async def _monitor_processes(self):
        """ãƒ—ãƒ­ã‚»ã‚¹ç›£è¦–"""
        try:
            # ä¸Šä½ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’å–å¾—
            top_processes = []
            
            for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent']):
                try:
                    pinfo = proc.info
                    
                    # CPUä½¿ç”¨ç‡ãŒé«˜ã„ãƒ—ãƒ­ã‚»ã‚¹ã‚’è¨˜éŒ²
                    if pinfo['cpu_percent'] > 5 or pinfo['memory_percent'] > 5:
                        # è©³ç´°æƒ…å ±å–å¾—
                        process_metrics = ProcessMetrics(
                            pid=pinfo['pid'],
                            name=pinfo['name'],
                            cpu_percent=pinfo['cpu_percent'],
                            memory_percent=pinfo['memory_percent'],
                            memory_info=proc.memory_info()._asdict(),
                            num_threads=proc.num_threads(),
                            status=proc.status(),
                            create_time=proc.create_time(),
                            io_counters=proc.io_counters()._asdict() if hasattr(proc, 'io_counters') else None,
                            open_files=len(proc.open_files()) if hasattr(proc, 'open_files') else 0,
                            connections=len(proc.connections()) if hasattr(proc, 'connections') else 0
                        )
                        
                        top_processes.append(process_metrics.__dict__)
                        
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue
            
            # CPUä½¿ç”¨ç‡ã§ã‚½ãƒ¼ãƒˆ
            top_processes.sort(key=lambda x: x['cpu_percent'], reverse=True)
            top_processes = top_processes[:10]  # ä¸Šä½10ãƒ—ãƒ­ã‚»ã‚¹
            
            # å±¥æ­´ã«è¿½åŠ 
            resource_metrics = ResourceMetrics(
                timestamp=datetime.now(),
                resource_type=ResourceType.PROCESS,
                metrics={'top_processes': top_processes},
                usage_percent=0  # ãƒ—ãƒ­ã‚»ã‚¹ã®å ´åˆã¯å€‹åˆ¥ã«ç®¡ç†
            )
            
            self.metrics_history[ResourceType.PROCESS].append(resource_metrics)
            
        except Exception as e:
            self.logger.error(f"Process monitoring error: {e}")
    
    async def _check_threshold(self, resource_type: ResourceType, metric_name: str, current_value: float):
        """ã—ãã„å€¤ãƒã‚§ãƒƒã‚¯"""
        try:
            thresholds = self.thresholds.get(resource_type.value, {})
            
            # ã‚¢ãƒ©ãƒ¼ãƒˆã‚­ãƒ¼
            alert_key = f"{resource_type.value}_{metric_name}"
            
            # ç¾åœ¨ã®ã‚¢ãƒ©ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«åˆ¤å®š
            alert_level = None
            threshold_value = None
            
            if current_value >= thresholds.get('critical', 100):
                alert_level = AlertLevel.CRITICAL
                threshold_value = thresholds['critical']
            elif current_value >= thresholds.get('warning', 100):
                alert_level = AlertLevel.WARNING
                threshold_value = thresholds['warning']
            
            # ã‚¢ãƒ©ãƒ¼ãƒˆå‡¦ç†
            if alert_level:
                if alert_key not in self.active_alerts:
                    # æ–°è¦ã‚¢ãƒ©ãƒ¼ãƒˆ
                    alert = Alert(
                        timestamp=datetime.now(),
                        resource_type=resource_type,
                        alert_level=alert_level,
                        metric_name=metric_name,
                        current_value=current_value,
                        threshold=threshold_value,
                        message=f"{resource_type.value} {metric_name} exceeded {alert_level.value} threshold: {current_value:.1f}% (threshold: {threshold_value}%)",
                        details={
                            'resource': resource_type.value,
                            'metric': metric_name,
                            'value': current_value,
                            'threshold': threshold_value
                        }
                    )
                    
                    self.active_alerts[alert_key] = alert
                    self.alert_history.append(alert)
                    self.stats['total_alerts'] += 1
                    self.stats['alerts_by_level'][alert_level.value] += 1
                    self.stats['alerts_by_type'][resource_type.value] += 1
                    
                    # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
                    await self._trigger_alert_callbacks(alert)
                    
                    self.logger.warning(alert.message)
                else:
                    # æ—¢å­˜ã‚¢ãƒ©ãƒ¼ãƒˆã®æ›´æ–°
                    existing_alert = self.active_alerts[alert_key]
                    existing_alert.current_value = current_value
                    
                    # ãƒ¬ãƒ™ãƒ«ãŒä¸ŠãŒã£ãŸå ´åˆ
                    if alert_level.value > existing_alert.alert_level.value:
                        existing_alert.alert_level = alert_level
                        existing_alert.message = f"{resource_type.value} {metric_name} escalated to {alert_level.value}: {current_value:.1f}%"
                        await self._trigger_alert_callbacks(existing_alert)
                        self.logger.warning(existing_alert.message)
            else:
                # ã—ãã„å€¤ä»¥ä¸‹ã®å ´åˆã€ã‚¢ãƒ©ãƒ¼ãƒˆè§£é™¤
                if alert_key in self.active_alerts:
                    alert = self.active_alerts[alert_key]
                    alert.resolved = True
                    alert.resolved_at = datetime.now()
                    del self.active_alerts[alert_key]
                    
                    self.logger.info(f"Alert resolved: {alert_key}")
            
        except Exception as e:
            self.logger.error(f"Threshold check error: {e}")
    
    async def _check_alerts(self):
        """ã‚¢ãƒ©ãƒ¼ãƒˆçŠ¶æ…‹ãƒã‚§ãƒƒã‚¯"""
        try:
            # é•·æ™‚é–“ç¶™ç¶šã—ã¦ã„ã‚‹ã‚¢ãƒ©ãƒ¼ãƒˆã®ç¢ºèª
            for alert_key, alert in list(self.active_alerts.items()):
                duration = datetime.now() - alert.timestamp
                
                # 30åˆ†ä»¥ä¸Šç¶™ç¶šã—ã¦ã„ã‚‹å ´åˆã¯ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ãƒˆ
                if duration > timedelta(minutes=30) and alert.alert_level != AlertLevel.EMERGENCY:
                    alert.alert_level = AlertLevel.EMERGENCY
                    alert.message = f"EMERGENCY: {alert.message} (continuing for {duration})"
                    await self._trigger_alert_callbacks(alert)
                    self.logger.error(alert.message)
            
        except Exception as e:
            self.logger.error(f"Alert check error: {e}")
    
    async def _analyze_trends(self):
        """ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        try:
            # å„ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã®ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
            for resource_type, history in self.metrics_history.items():
                if len(history) < 10:
                    continue
                
                # æœ€è¿‘ã®ãƒ‡ãƒ¼ã‚¿
                recent_data = list(history)[-60:]  # ç›´è¿‘1åˆ†
                
                if resource_type in [ResourceType.CPU, ResourceType.MEMORY, ResourceType.DISK]:
                    # ä½¿ç”¨ç‡ã®ãƒˆãƒ¬ãƒ³ãƒ‰
                    usage_values = [m.usage_percent for m in recent_data]
                    
                    if len(usage_values) >= 10:
                        # ç§»å‹•å¹³å‡
                        avg_usage = np.mean(usage_values)
                        
                        # ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆå¢—åŠ /æ¸›å°‘ï¼‰
                        trend = np.polyfit(range(len(usage_values)), usage_values, 1)[0]
                        
                        # æ€¥æ¿€ãªå¢—åŠ ã‚’æ¤œå‡º
                        if trend > 1.0:  # 1%/ç§’ä»¥ä¸Šã®å¢—åŠ 
                            self.logger.warning(f"{resource_type.value} usage increasing rapidly: {trend:.2f}%/s")
                            
                            # äºˆæ¸¬ï¼šã“ã®ã¾ã¾ç¶šãã¨ä½•åˆ†å¾Œã«100%ã«é”ã™ã‚‹ã‹
                            if avg_usage < 100:
                                minutes_to_full = (100 - avg_usage) / (trend * 60)
                                if minutes_to_full < 10:
                                    self.logger.warning(f"{resource_type.value} will reach 100% in {minutes_to_full:.1f} minutes")
            
        except Exception as e:
            self.logger.error(f"Trend analysis error: {e}")
    
    async def _trigger_alert_callbacks(self, alert: Alert):
        """ã‚¢ãƒ©ãƒ¼ãƒˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ"""
        for callback in self.alert_callbacks:
            try:
                if asyncio.iscoroutinefunction(callback):
                    await callback(alert)
                else:
                    await asyncio.get_event_loop().run_in_executor(self.executor, callback, alert)
            except Exception as e:
                self.logger.error(f"Alert callback error: {e}")
    
    def add_alert_callback(self, callback: Callable):
        """ã‚¢ãƒ©ãƒ¼ãƒˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¿½åŠ """
        self.alert_callbacks.append(callback)
    
    async def get_current_metrics(self) -> Dict[str, Any]:
        """ç¾åœ¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—"""
        current = {}
        
        for resource_type, history in self.metrics_history.items():
            if history:
                latest = history[-1]
                current[resource_type.value] = {
                    'timestamp': latest.timestamp.isoformat(),
                    'usage_percent': latest.usage_percent,
                    'status': latest.status,
                    'metrics': latest.metrics
                }
        
        return current
    
    async def get_metrics_history(self, resource_type: ResourceType, duration: timedelta = None) -> List[Dict[str, Any]]:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹å±¥æ­´å–å¾—"""
        history = self.metrics_history.get(resource_type, [])
        
        if duration:
            cutoff_time = datetime.now() - duration
            filtered_history = [m for m in history if m.timestamp > cutoff_time]
        else:
            filtered_history = list(history)
        
        return [
            {
                'timestamp': m.timestamp.isoformat(),
                'usage_percent': m.usage_percent,
                'metrics': m.metrics
            }
            for m in filtered_history
        ]
    
    async def get_resource_report(self) -> Dict[str, Any]:
        """ãƒªã‚½ãƒ¼ã‚¹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        try:
            # ç¾åœ¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            current_metrics = await self.get_current_metrics()
            
            # çµ±è¨ˆæƒ…å ±
            uptime = datetime.now() - self.stats['start_time'] if self.stats['start_time'] else timedelta(0)
            
            # å„ãƒªã‚½ãƒ¼ã‚¹ã®å¹³å‡ä½¿ç”¨ç‡
            average_usage = {}
            peak_usage = {}
            
            for resource_type, history in self.metrics_history.items():
                if history and resource_type != ResourceType.PROCESS:
                    usage_values = [m.usage_percent for m in history]
                    average_usage[resource_type.value] = np.mean(usage_values)
                    peak_usage[resource_type.value] = max(usage_values)
            
            return {
                'status': 'monitoring' if self.is_monitoring else 'stopped',
                'uptime': str(uptime),
                'current_metrics': current_metrics,
                'average_usage': average_usage,
                'peak_usage': peak_usage,
                'active_alerts': len(self.active_alerts),
                'total_alerts': self.stats['total_alerts'],
                'alerts_by_level': dict(self.stats['alerts_by_level']),
                'alerts_by_type': dict(self.stats['alerts_by_type']),
                'system_info': {
                    'platform': platform.platform(),
                    'cpu_count': psutil.cpu_count(),
                    'total_memory': psutil.virtual_memory().total,
                    'boot_time': datetime.fromtimestamp(psutil.boot_time()).isoformat()
                }
            }
            
        except Exception as e:
            self.logger.error(f"Resource report generation error: {e}")
            return {'error': str(e)}
    
    async def export_metrics(self, output_path: Path, duration: timedelta = None) -> bool:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        try:
            export_data = {
                'timestamp': datetime.now().isoformat(),
                'report': await self.get_resource_report(),
                'metrics_history': {}
            }
            
            # å„ãƒªã‚½ãƒ¼ã‚¹ã®å±¥æ­´
            for resource_type in ResourceType:
                history = await self.get_metrics_history(resource_type, duration)
                export_data['metrics_history'][resource_type.value] = history
            
            # ã‚¢ãƒ©ãƒ¼ãƒˆå±¥æ­´
            export_data['alert_history'] = [
                {
                    'timestamp': alert.timestamp.isoformat(),
                    'resource_type': alert.resource_type.value,
                    'alert_level': alert.alert_level.value,
                    'metric_name': alert.metric_name,
                    'current_value': alert.current_value,
                    'threshold': alert.threshold,
                    'message': alert.message,
                    'resolved': alert.resolved,
                    'resolved_at': alert.resolved_at.isoformat() if alert.resolved_at else None
                }
                for alert in self.alert_history
            ]
            
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_path, 'w') as f:
                json.dump(export_data, f, indent=2, default=str)
            
            self.logger.info(f"Metrics exported to {output_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"Metrics export error: {e}")
            return False
    
    def __del__(self):
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        self.executor.shutdown(wait=False)


# ãƒªã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒ¼ã®ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼é–¢æ•°
def create_resource_monitor(config: Optional[Dict[str, Any]] = None) -> ResourceMonitor:
    """ãƒªã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒ¼ä½œæˆ"""
    return ResourceMonitor(config)


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    async def test_resource_monitor():
        # è¨­å®š
        config = {
            'interval': 1.0,
            'thresholds': {
                'cpu': {'warning': 50, 'critical': 80},
                'memory': {'warning': 60, 'critical': 90},
                'disk': {'warning': 70, 'critical': 90}
            }
        }
        
        monitor = create_resource_monitor(config)
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
        def alert_handler(alert: Alert):
            print(f"ğŸš¨ ALERT: {alert.message}")
        
        monitor.add_alert_callback(alert_handler)
        
        # ç›£è¦–é–‹å§‹
        print("Starting resource monitoring...")
        await monitor.start_monitoring()
        
        # 10ç§’é–“ç›£è¦–
        await asyncio.sleep(10)
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = await monitor.get_resource_report()
        print("\nResource Report:")
        print(json.dumps(report, indent=2))
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        export_path = Path.home() / '.claude' / 'monitoring' / 'resource_metrics.json'
        await monitor.export_metrics(export_path)
        print(f"\nMetrics exported to: {export_path}")
        
        # ç›£è¦–åœæ­¢
        await monitor.stop_monitoring()
        print("Resource monitoring stopped")
    
    asyncio.run(test_resource_monitor())